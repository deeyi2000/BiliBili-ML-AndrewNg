<?xml version="1.0" encoding="UTF-8"?><i><chatserver>chat.bilibili.com</chatserver><chatid>88849309</chatid><mission>0</mission><maxlimit>1500</maxlimit><state>0</state><real_name>0</real_name><source>k-v</source><d p="95.97200,1,25,16777215,1604406320,0,36401e7a,40508664143937539">其他8个人能看到吗</d><d p="77.51500,1,25,16777215,1604406304,0,36401e7a,40508655719153671">现在9个人</d><d p="511.99900,1,25,16777215,1604398327,0,4a80f9a7,40504473865945093">就是套娃套娃套娃呗！！！！！！！！！！！！！！！</d><d p="275.22300,1,25,16777215,1604285979,0,250909b0,40445570972647427">so easy</d><d p="526.89900,1,25,13369971,1604065503,0,b3167749,40329978174242819">所以这本质上是一个特征工程。从原始数据X挖掘出一层比一层有用的特征A1, A2, ...  最后使用逻辑回归线性拟合得出预测</d><d p="314.70800,1,25,16777215,1604062705,0,2464455,40328511002509317">听不懂了</d><d p="303.04300,1,25,16777215,1604062689,0,2464455,40328502891249667">这里就听不懂了</d><d p="587.53700,1,25,16777215,1604018888,0,7ae8a5a,40305538450325511">看，果然不是我的问题，老师也知道我听不懂</d><d p="580.84700,1,25,16777215,1603973499,0,b7b8d71e,40281741279625219">感觉像动态规划</d><d p="559.74200,1,25,16777215,1603963175,0,3abb9f36,40276328791408645">buneng</d><d p="5.17900,1,25,16777215,1603787828,0,8e61f082,40184396572000261">你，np，你咋不上天呢</d><d p="157.44200,1,25,16777215,1603716620,0,e3394ede,40147062824632325">秒啊</d><d p="578.34400,1,25,16777215,1603701252,0,4bb2cd6,40139005643718659">不会的举个手，给个安慰</d><d p="43.50600,1,25,16777215,1603697133,0,4bb2cd6,40136846070513667">金长龙nb！！</d><d p="128.33400,1,25,16777215,1603695139,0,c260dbbf,40135800491868167">theta为什么从10开始，看都好茫然</d><d p="493.57400,1,25,16777215,1603682517,0,3f5e339a,40129182840127493">concretely</d><d p="642.06900,1,25,16777215,1603262414,0,3d268ffb,39908927996428293">其实我在第五层</d><d p="156.88800,1,25,16777215,1603187721,0,1787402c,39869767333969925">喵啊。</d><d p="289.60100,1,25,16777215,1602683140,0,3925e593,39605221583749123">在看的10人你们好啊</d><d p="195.18200,1,25,16777215,1602682887,0,960b8744,39605088971915267">说没看懂的xd,你作业是不是没做</d><d p="664.11300,1,25,16777215,1602500642,0,4ec77685,39509540459249671">层数没有限制，看你自己愿意</d><d p="533.45400,1,25,16777215,1602394194,0,ea8195df,39453731016146947">就像是直接按字母背单词，和经过一定的研究和分类得到词根词缀的规律，再背单词吧，效果会好一些</d><d p="48.89900,1,25,16777215,1602393034,0,ea8195df,39453122723577859">明显不一样，看大theta的上标</d><d p="110.55100,1,25,16777215,1602208204,0,40cc218c,39356218342899715">一脸懵逼啊</d><d p="116.00800,1,25,16777215,1602128186,0,fb2bdd2b,39314265966379015">6个！</d><d p="351.14000,1,25,16777215,1602018882,0,d8bab795,39256959060279301">转移矩阵</d><d p="349.65800,1,25,16777215,1602018874,0,d8bab795,39256955006484485">有点类似于转换矩阵</d><d p="197.27200,1,25,16777215,1601388529,0,ce4d7942,38926472593801223">不得不说在座的各位都是lj</d><d p="1.09900,1,25,16777215,1601388275,0,ce4d7942,38926339523739655">我一个学会科学的文科生都能听懂，您们怎么这么菜</d><d p="343.51800,1,25,16777215,1601296184,0,b25c44c3,38878057529868295">取决于变量数</d><d p="311.59800,1,25,16777215,1601296135,0,b25c44c3,38878031620079621">建议大家手推一次，就好理解了</d><d p="47.54500,1,25,16777215,1600863393,0,14a83c35,38651150142013447">这里两次计算用的函数和参数都一样吗</d><d p="69.04500,1,25,16777215,1600822826,0,9777a26c,38629881396330503">上课就上课，刷什么存在感？？</d><d p="341.44900,1,25,16777215,1600698148,0,e1c8e29d,38564514503327747">会随着每层的单元数改变</d><d p="679.91600,1,25,16777215,1600615946,0,780f0d71,38521416858468359">前面有讲啊，出了输入层与输出层，其他全是隐藏层</d><d p="605.78400,1,25,16777215,1600600068,0,9f088233,38513092300636167">这节课真的标题党，一开始号称要说为什么神经网络可以提高找特征的效率，结果只说了一个两层神经网络是优化后的逻辑回归</d><d p="327.69000,1,25,16777215,1600599721,0,9f088233,38512909953269767">但是对于算法本身的复杂度来说，让多次迭代的函数在像空间中分布达到ergodic的效率是远远高于一次的，可能这是多层神经网络有用的原因</d><d p="327.69000,1,25,16777215,1600599648,0,9f088233,38512871892058115">纵观我熟悉的数学证明，一层神经网络的有很多，但是两层的一个都找不到。两层无非是加了另外的非线性函数进行迭代但是对于数学来说这似乎并不重要，因为数学里面所有东西都可以用一层来表达。</d><d p="91.05900,1,25,16777215,1600479633,0,fe6e24ee,38449949286334469">有人吗</d><d p="565.34600,1,25,16777215,1600268696,0,9c35e216,38339357900800007">那么theta怎么算呢</d><d p="359.22900,5,25,38979,1599858814,0,489fa0db,38124461641170951">我是一位爱丁堡的学生 真的觉得不难 看见这条的发个pyq我会告诉你我是谁</d><d p="563.54900,1,25,16777215,1599553483,0,e29d5e7a,37964380015951875">这个最好的示例应该是过拟合中的最后一个</d><d p="541.71800,1,25,16777215,1599553415,0,e29d5e7a,37964344409456645">这样应该可以更加精准的拟合出非线性函数吧</d><d p="398.77000,1,25,16777215,1599553220,0,e29d5e7a,37964242133450759">没懂如何帮助非线性了</d><d p="307.14700,1,25,16777215,1599480204,0,490ed039,37925960763834371">是1*4吧</d><d p="74.56000,1,25,16777215,1599052527,0,6dddbbf0,37701734963871749">大家开学没</d><d p="463.37400,1,25,16777215,1598595935,0,3df82069,37462349038747653">这还不太懂? 我觉得初中生都能听懂</d><d p="150.06400,1,25,16777215,1598370130,0,a781365e,37343962243530757">听上一讲的时候就推出来了，果然是这样</d><d p="92.04300,1,25,16777215,1598062458,0,205339de,37182653399040003">NIHAO</d><d p="294.19200,1,25,16777215,1597996906,0,63ead830,37148285582966787">还没学线性代数，表示看懂了</d><d p="595.36100,1,25,16777215,1597657429,0,4c910636,36970301532143623">幼儿园毕业表示听不懂</d><d p="427.71300,1,25,16777215,1597647778,0,d21956ed,36965241599819783">不是简单的套娃？</d><d p="92.80600,1,25,16777215,1597240357,0,61cc1d0,36751635949551623">2020 8 12</d><d p="463.16300,1,25,16777215,1597199332,0,be560c3d,36730127181676551">自己在草稿纸上算一下就清楚了</d><d p="695.43400,1,25,16777215,1597062060,0,abb8476d,36658156838322183">继续估房价</d><d p="636.02700,1,25,16777215,1596702459,0,7a857d85,36469622444130311">池化吧？</d><d p="311.76400,1,25,16777215,1596702295,0,7a857d85,36469536464044035">没毛病</d><d p="530.28600,1,25,16777215,1596620245,0,35feb039,36426518542417927">这个点不懂，为什么会比之前的数据更好得到的假设更好呢</d><d p="554.59700,1,25,16777215,1596545879,0,57ca5717,36387529190014981">讲的好乱啊</d><d p="182.68600,1,25,16777215,1596444770,0,d74e6d1c,36334519389257797">数学的魔力</d><d p="93.15700,1,25,16777215,1596444350,0,d74e6d1c,36334299087110147">刚入门</d><d p="588.85000,1,25,16777215,1596357396,0,8eb9afd6,36288710037733379">小学双100选手表示可以理解</d><d p="61.65900,1,25,16777215,1596079500,0,acce73c,36143012574658567">加油</d><d p="602.87800,5,25,16646914,1596078869,0,916f83f3,36142681868992517">抱歉，我们学高代和数分</d><d p="304.56300,1,25,16777215,1595927581,0,ff89b7df,36063363279093765">讲错了，是1*4的行向量</d><d p="302.43200,1,25,16777215,1595927134,0,ff89b7df,36063128986845191">这里的theta2应该是1*3的行向量</d><d p="7.71300,5,25,16646914,1595849254,0,973c5451,36022297492455431">46/112</d><d p="635.20700,1,25,16777215,1595756299,0,1d70ef52,35973562314522629">五年级小学生表示能理解</d><d p="185.17300,1,25,16777215,1595740511,0,98793612,35965284534714371">做完作业ex1、ex2之后再过来看理解起来就容易多了哎~</d><d p="208.06300,1,25,16777215,1595702092,0,879d771b,35945142235955207">看不懂的说明线代没学好</d><d p="605.72800,1,25,16777215,1595479191,0,114b98de,35828277923807235">大师，我什么时候才能顿悟</d><d p="380.60300,1,25,16777215,1595478869,0,114b98de,35828108729778181">大师，我悟了</d><d p="181.08200,1,25,16777215,1595474912,0,5de956e2,35826034100142083">x本来就是列向量</d><d p="609.40000,1,25,16777215,1595307794,0,8f77050f,35738416508829699">每天写2000首诗的小神童理解了</d><d p="603.99600,1,25,16777215,1595140855,0,66ff1191,35650891975491587">抽烟就完事了 老吴</d><d p="592.75800,1,25,16777215,1595140834,0,66ff1191,35650881280016387">兄弟们，抽烟抽起来</d><d p="433.56200,1,25,16777215,1595140665,0,66ff1191,35650792770240517">禁止套娃</d><d p="344.86200,1,25,16777215,1595140569,0,66ff1191,35650742165438467">人上人清华大学计算机与金融专业学生前来报道</d><d p="250.96000,1,25,16777215,1595140458,0,66ff1191,35650683892924423">T大计算机与金融专业前来报道</d><d p="403.27400,1,25,16777215,1595122305,0,a32d3583,35641166573076483">因为有激活函数所以是逻辑回归</d><d p="702.79800,1,25,16777215,1595063844,0,6ccb74c6,35610516477444103">我也觉得我听懂了 就是套娃</d><d p="276.97900,5,25,15138834,1594996640,0,31136bfc,35575282273878087">听懂了</d><d p="194.55800,1,25,16777215,1594816963,0,e1f7ee93,35481079476912133">用python的numpy计算不需要转置，可以直接广播</d><d p="586.01200,1,25,16777215,1594732227,0,df627807,35436653708312645">不，你不会</d><d p="636.54300,1,25,16777215,1594692750,0,b4926146,35415955966263303">我觉得也是加入了sigmoid函数才有意义，否则都是用原向量左乘一个矩阵了</d><d p="277.54500,1,25,16777215,1593856793,0,49b0f379,34977673918283781">还真没懂</d><d p="98.02500,1,25,16777215,1593757162,0,85bc2782,34925438543855683">你好</d><d p="82.13700,1,25,16777215,1593586428,0,336baec3,34835924993441797">6个朋友你们好啊</d><d p="618.59700,1,25,16777215,1593504549,0,12fb4a99,34792996542087173">太难了</d><d p="196.05200,1,25,16777215,1593503665,0,12fb4a99,34792532839759877">看不懂怎么办啊啊啊</d><d p="61.75900,1,25,16777215,1593503326,0,12fb4a99,34792355617308677">6个了</d><d p="54.15600,1,25,16777215,1593503319,0,12fb4a99,34792351672041479">看得见吗？5个正在看的人？</d><d p="400.16900,1,25,16777215,1593397027,0,f19f9d89,34736624072392707">懵</d><d p="463.86900,1,25,16777215,1592971528,0,17e6896c,34513539986620421">在这里说是逻辑回归只是因为激活函数是sigmod而已，只是举个例子</d><d p="273.04800,1,25,16777215,1592838947,0,1774991b,34444029236084741">你们都能听懂吗</d><d p="592.32300,1,25,16777215,1592658729,0,5ad18398,34349543508672515">满分150，哈哈</d><d p="512.56400,1,25,16777215,1592658613,0,5ad18398,34349482627301383">这是stacking一层层提取特征，不是分而治之</d><d p="476.45600,1,25,16777215,1592658552,0,5ad18398,34349450447552515">第一层就是直接输入的输入空间，然后得到了第二层，特征空间，特征空间再作为输入</d><d p="189.89700,1,25,16777215,1592640119,0,92f05439,34339786439786499">咋就三维了，求解释</d><d p="28.83000,1,25,16777215,1592637408,0,7246164d,34338364961325063">国外网站，视频根本看不了</d><d p="499.81800,1,25,16777215,1592297928,0,bd93ee1,34160379762835459">妙啊</d><d p="637.40400,1,25,16777215,1592144640,0,88f90dab,34080012471107591">事实上，我在第五层</d><d p="595.30100,1,25,16777215,1591869908,0,b5dadf35,33935973970608131">感觉这节课也没说啥啊</d><d p="517.79600,1,25,16777215,1591867120,0,9e6f61f8,33934512201138181">套一层我都要理解半天，套这么多层不是为难我胖虎嘛</d><d p="325.11900,1,25,16777215,1591866726,0,9e6f61f8,33934305715552261">前一层偏置项会影响下一层，但是下一层的偏置项不受前一层的影响</d><d p="507.21100,1,25,16777215,1591791813,0,ab516041,33895029558214659">这该怎么求theta</d><d p="638.39100,1,25,16777215,1591239509,0,d8e1c10d,33605463519526915">秒啊，现在才领悟马老c的意思</d><d p="589.82000,1,25,16777215,1590914336,0,44dcb7ab,33434978780446723">似懂非懂+1</d><d p="567.11200,1,25,16777215,1590853299,0,53dc64d5,33402978054963203">我会了</d><d p="213.38800,1,25,16777215,1590852215,0,53dc64d5,33402409716285443">这里将复杂了，可以理解为权重矩阵乘输入</d><d p="289.88200,1,25,16755202,1590545116,0,716d3933,33241401256312835">图上画的那三个层分别是a1a2a3再加上两个偏执的a0</d><d p="639.92400,1,25,16777215,1590487813,0,27135200,33211357896638467">我懂了</d><d p="340.97400,1,25,16777215,1590426209,0,4572fdc5,33179059941801991">参数矩阵只跟这一层和上一层有关</d><d p="279.03300,1,25,16777215,1590394880,0,26d30b9c,33162634454368259">哈哈哈哈，我看懂了</d><d p="420.50800,1,25,16777215,1590383568,0,7df2f5f6,33156703576391683">所以之前那个说学习前面的线性和逻辑回归没用的就是憨批</d><d p="202.08300,1,25,16777215,1590382226,0,7df2f5f6,33155999948865539">说要转的为你们感到丢人 学到哪去了</d><d p="561.53600,1,25,16777215,1590023998,0,5e7181f1,32968185590841347">逻辑回归套碗</d><d p="593.39800,1,25,16776960,1589914194,0,6a590cdf,32910616516100103">秀成绩的秀啥优越感呢？</d><d p="503.83400,1,25,16777215,1589853884,0,3ffda7e6,32878996638138375">套娃套娃套娃</d><d p="575.87600,1,25,16777215,1589853692,0,3ffda7e6,32878896218112005">不停的套娃套娃</d><d p="633.93600,1,25,16777215,1589818797,0,cf081f11,32860601021104133">要是中间不用sigmoid函数是不是最后还是线性的</d><d p="513.22900,1,25,16777215,1589818342,0,cf081f11,32860362570203143">原来是这样</d><d p="477.03500,1,25,16777215,1589813892,0,739f5ffc,32858029631209477">套娃回归</d><d p="581.65700,1,25,16777215,1589709612,0,dca36827,32803356752740355">这已经是最基础的神经网络了</d><d p="697.74800,1,25,16777215,1589630709,0,eb44f612,32761988681564167">除了输入输出层 其他都是隐藏层</d><d p="591.70000,1,25,16777215,1589629354,0,eb44f612,32761278293344263">自己写一下 还是很清楚的</d><d p="360.29700,1,25,16777215,1589540022,0,485f3d1b,32714442918068231">好难啊这章</d><d p="413.75800,1,25,16777215,1589505977,0,ee6ea4f3,32696593307664387">如果用c来写，需要自己用三层for循环来实现，复杂度很高</d><d p="413.75800,1,25,16777215,1589505954,0,ee6ea4f3,32696581339742213">向量化的好处就是在于可以并行化计算，你用numpy或者matlab就可以直接算矩阵相乘</d><d p="351.74800,1,25,16777215,1589505856,0,ee6ea4f3,32696529815339013">每一层都有每一层的参数矩阵，这都是需要通过反向传播来学习的</d><d p="206.07900,1,25,16777215,1589505649,0,ee6ea4f3,32696421354307587">theta1是3*4的矩阵 ，x是4*1的矩阵，所以 z2 是3*1的矩阵</d><d p="537.56400,1,25,16777215,1589340072,0,fa6a41c,32609611361550341">这只是 简单的前向传播，神经网络应该不止这一种</d><d p="508.79200,1,25,16777215,1589340004,0,fa6a41c,32609575695286277">层层递进 逐步深入 得出output</d><d p="180.98600,1,25,16777215,1589004646,0,b2634b65,32433751237591043">这也能妙。。。。。</d><d p="696.50300,1,25,16777215,1588991526,0,a17197b,32426873041453059">我想说我全听懂了，当然只是想想</d><d p="433.42500,1,25,16777215,1588820811,0,56945880,32337369164152839">不懂得可以问我</d><d p="379.33100,1,25,16777215,1588820739,0,56945880,32337331377668101">说实话，神经网络这两节，感觉有点跳跃。没有前面的课循序渐进</d><d p="35.94500,1,25,16777215,1588820351,0,56945880,32337127692828677">x 和 a 之间的每一条连线，都对应一个参数值theta , 这些参数值构成矩阵theta</d><d p="576.79600,1,25,16777215,1588505102,0,5f53e7b,32171846310297605">这节课其实也就讲了如何用矩阵表示神经网络，多看两遍就清楚了</d><d p="22.06400,1,25,16777215,1588154374,0,ec936688,31987964271656963">Coursera卡到爆炸！！！</d><d p="500.87200,1,25,16777215,1588141185,0,76582a6a,31981049237995591">隐藏层是不是用一个矩阵对X做线性组合得到a，之后再对得到的a进行线性组合？</d><d p="207.60900,1,25,16777215,1587970380,0,14148931,31891498075160583">看不懂</d><d p="610.43600,1,25,16777215,1587902204,0,a9281c7c,31855754471276547">不是很难吧</d><d p="643.07000,1,25,16777215,1587645512,0,7e91fd04,31721173907144709">矩阵真的是个伟大的发明</d><d p="595.80700,1,25,16777215,1587645455,0,7e91fd04,31721143800954885">小学数学语文双百表示可以理解</d><d p="197.99200,1,25,16777215,1587627009,0,11842019,31711472728932359">、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、</d><d p="502.83800,1,25,16777215,1587547971,0,a424bc3f,31670034240634883">有点分而治之的感觉</d><d p="467.33700,1,25,16777215,1587452974,0,ba32d8cd,31620228663738371">问一下这里的大theta和之前的小theta在数值上应该是一样的吧（不懂就问）</d><d p="658.59300,1,25,16777215,1587434967,0,372f0c7c,31610787486236679">大概是直觉</d><d p="475.28900,1,25,16777215,1587434075,0,372f0c7c,31610319818194947">多层逻辑回归，上层逻辑回归的结果被下层逻辑回归当做特征</d><d p="408.73000,1,25,16777215,1587433868,0,372f0c7c,31610211620356101">这些数学库往往由专业的大佬们高度优化过</d><d p="408.73000,1,25,16777215,1587433828,0,372f0c7c,31610190600601603">写成矩阵相乘就可以在代码中直接使用数学库计算</d><d p="700.28100,1,25,16777215,1587352593,0,7545633d,31567599928606723">这些知识对我来说确实高端</d><d p="696.93400,1,25,16777215,1587352578,0,7545633d,31567592067432453">老师真好</d><d p="593.24000,1,25,16777215,1587352468,0,7545633d,31567534363770887">我大概不太能理解</d><d p="433.27500,1,25,16777215,1587352219,0,7545633d,31567403886837829">神经网络套娃</d><d p="389.79000,1,25,16777215,1587352176,0,7545633d,31567381097611271">五脸懵逼</d><d p="345.37100,1,25,16777215,1587283026,0,e994e085,31531126966190083">当然改变，每一层的每一个输入特征的权重可能是不一样的吧</d><d p="293.91000,1,25,16777215,1587105753,0,46f4ef83,31438184626257927">二刷加手动列出theta ,,a,,各种数据,才懂的,神奇,真的得动手自己弄下.....毕竟工科狗没学高代...</d><d p="581.97800,1,25,16777215,1586700790,0,7e32f6c4,31225867607212037">勉强理解 老师讲得真好</d><d p="286.15900,1,25,16777215,1586700136,0,7e32f6c4,31225524265156611">淦 之前好不容易听明白到这又不懂了</d><d p="169.02200,1,25,16777215,1586684561,0,a09dce03,31217358520975367">秒啊</d><d p="367.15500,1,25,16777215,1586658290,0,e18e943a,31203585390280837">四脸萌比</d><d p="463.92300,1,25,16777215,1586612054,0,1201ff5f,31179344272424967">＋1</d><d p="182.06800,1,25,16777215,1586584545,0,d32da7f3,31164921616007175">不用转置的，只是用z来代替括号中的式子</d><d p="181.39300,1,25,16777215,1586584262,0,d32da7f3,31164773152849925">要转置的，不然怎么进行矩阵计算</d><d p="667.91400,1,25,16777215,1586337408,0,8572425a,31035350511517699">好问题</d><d p="581.34600,1,25,16777215,1586337316,0,8572425a,31035302605225989">多看几遍吧，会理解的</d><d p="550.36600,1,25,16777215,1586337250,0,8572425a,31035267839688709">套娃了若干个逻辑回归</d><d p="414.65500,1,25,16777215,1586337050,0,8572425a,31035163026128901">套娃我笑了。。。</d><d p="302.79900,1,25,16777215,1586336901,0,8572425a,31035084825427971">这是很基本的矩阵乘法，自己编程非常实用</d><d p="286.01500,1,25,16777215,1586270433,0,4da47994,31000236598493191">这集最好自己写写，真正搞清楚什么是a,z,theta和他们之间的关系</d><d p="457.25200,1,25,16777215,1586214896,0,f4725f5b,30971119008219139">不太懂，接着看吧</d><d p="399.90400,1,25,16777215,1586214839,0,f4725f5b,30971088926670853">完全不懂</d><d p="640.92800,1,25,16777215,1585907759,0,cf6f8d77,30810090933583875">theta 反向传播可以计算出来</d><d p="409.60300,1,25,16777215,1585907131,0,cf6f8d77,30809761309523973">构建一个隐藏层来选择合适的合适的组合 这样子就减少组合规模</d><d p="409.60300,1,25,16777215,1585906981,0,cf6f8d77,30809683085754373">你看这里的神经网络其实挡住一部分就是逻辑回归了</d><d p="351.73000,1,25,16777215,1585906728,0,cf6f8d77,30809550180843527">会啊</d><d p="253.46200,1,25,16777215,1585906599,0,cf6f8d77,30809482525671427">偏值</d><d p="594.47000,1,25,16777215,1585844762,0,95820e35,30777062414352387">前几章基础知识的具象化，非常有意思</d><d p="420.48900,1,25,16777215,1585797515,0,a936785f,30752290959785987">老千层饼了</d><d p="627.07900,1,25,16777215,1585743750,0,41708cc7,30724102790578183">第二层、第五层</d><d p="584.29400,1,25,16777215,1585717742,0,c770d041,30710467275522053">工科生裂开了</d><d p="666.25000,1,25,16777215,1585577505,0,977afb10,30636942636351491">一个输入层，一个输出层，其他是隐含层吧</d><d p="154.10400,1,25,16777215,1585460578,0,408624b4,30575638901948421">秒啊</d><d p="592.37000,1,25,16777215,1585386095,0,93c9d79e,30536588288589827">我好希望老师现在再说that's ok哈哈哈哈</d><d p="282.10500,1,25,16777215,1585385566,0,93c9d79e,30536310932897795">有点听不懂</d><d p="571.70100,1,25,16777215,1585298914,0,2bb9700c,30490880867565573">不能……我死了</d><d p="693.58200,1,25,16777215,1585243849,0,dc83726,30462010899038215">高端</d><d p="643.42400,1,25,16777215,1585243783,0,dc83726,30461975908581383">每次都加一个偏置项，那它的维度是怎么变小的？感觉theta会变化</d><d p="401.84900,1,25,16777215,1585243228,0,dc83726,30461685213429767">懂是懂了七八层但是这个矩阵乘来乘去是为了干啥</d><d p="337.29800,1,25,16777215,1585243067,0,dc83726,30461600599113733">theta这个参数矩阵会随着层数的增加而改变吗？</d><d p="591.46900,1,25,16777215,1585127664,0,6060738f,30401096560672771">我认为就是通过前几层的训练，训练出特征之间的关系，从而可以选取合适的特征组合进行训练</d><d p="510.80700,1,25,16777215,1585067431,0,668d30e7,30369517004128259">激活函数有很多种  不一定是sigmoid</d><d p="73.89200,1,25,16777215,1584975699,0,a244fee8,30321423004205059">感谢解释</d><d p="145.99200,1,25,16777215,1584945421,0,7667529e,30305548453806083">wow</d><d p="404.63200,1,25,16777215,1584943629,0,1ec90e25,30304609282031619">禁止套娃！！！</d><d p="309.65300,1,25,16777215,1584934789,0,af184572,30299974149865477">这里theta^(2)是1*4的矩阵，theta的维度是下一层的元素个数*本层元素个数加一</d><d p="639.17400,1,25,16777215,1584861103,0,7127bb94,30261341397188613">就是提取特征</d><d p="657.05300,1,25,16777215,1584783465,0,53cddc92,30220636839215107">隐藏层的层数是怎么确定的啊</d><d p="192.55300,1,25,16777215,1584782177,0,53cddc92,30219961554174023">说theta是列向量的把我看笑了，让我有勇气看下去了，多谢</d><d p="631.25600,1,25,16777215,1584629424,0,4c1b69ee,30139875389865991">创始者有很强的思维逻辑啊！</d><d p="538.37000,1,25,16777215,1584629328,0,4c1b69ee,30139824789258245">神经网络即为立体的logistic回归</d><d p="150.66300,1,25,16777215,1584613981,0,4c1b69ee,30131778690220035">妙啊</d><d p="392.19700,1,25,16777215,1584527384,0,9f70df2e,30086376929624071">老师很喜欢说concretely哈哈</d><d p="71.20800,1,25,16777215,1584521035,0,9f70df2e,30083047954579461">大theta的第一个下标表示到哪里去，第二个下标表示从哪里来</d><d p="218.66000,1,25,16777215,1584520627,0,9f70df2e,30082834001559559">theta是3X4， x是4X1，直接乘，满足矩阵运算法则</d><d p="107.40000,1,25,16777215,1584520428,0,9f70df2e,30082729479503877">z已经是上一次线性组合的结果了，再加一个函数，变成a</d><d p="634.99500,1,25,16777215,1584519881,0,668d30e7,30082443120214019">应该是因为可以一层一层地筛出有效特征？</d><d p="663.13300,1,25,16777215,1584517860,0,3a4add14,30081383395753989">调参是个问题</d><d p="609.63100,1,25,16777215,1584517803,0,3a4add14,30081353302147139">讲的很清晰了吧 就是分层</d><d p="64.50700,1,25,15658734,1584492231,0,9bb38582,30067946362503171">.</d><d p="370.25700,1,25,16777215,1584365802,0,3433b8c,30001661298081795">我懂了哈哈哈</d><d p="648.24800,1,25,16777215,1584325700,0,2766db90,29980635956248581">theta值是后期训练出来的</d><d p="191.11800,1,25,16777215,1584275655,0,24cd587e,29954398147313667">不要口吐芬芳 不用 theta是3*4 x是4*1</d><d p="392.41600,1,25,16777215,1584235418,0,9bb15f07,29933302677241863">为什么不是像线性回归呢</d><d p="190.89600,1,25,16777215,1584008504,0,b4281a13,29814334084874247">theta这里直接是矩阵，不用转</d><d p="605.92500,1,25,16777215,1583863345,0,c570886f,29738229313830917">这些东西都是怎么发明出来的啊 这是人能创造的东西吗</d><d p="211.26700,1,25,16777215,1583847054,0,f409aaa4,29729687998562307">不转置啊4个列向量正好</d><d p="306.18300,1,25,16777215,1583660396,0,ba416e38,29631825566498823">线代不好确实有压力</d><d p="627.01700,1,25,16777215,1583572485,0,b7311062,29585734512934917">同问</d><d p="353.25800,1,25,16777215,1583556103,0,cec65d47,29577145786826759">感觉和矩阵乘法的关系很紧密</d><d p="197.17600,1,25,16777215,1583548511,0,e78a5fc6,29573165528645639">theta是单个列向量才要转置</d><d p="378.28400,1,25,16777215,1583408096,0,483b0203,29499547204452355">懂了该怎么实际操作使用</d><d p="359.32100,1,25,16777215,1583403579,0,bb208a6f,29497179208941573">三脸懵逼</d><d p="209.01100,1,25,16777215,1583399009,0,4f4d65c1,29494783170314243">之前x的特征向量不是列么</d><d p="637.14300,1,25,16777215,1583377632,0,cc4aae06,29483575559585799">那难点是在于如何根据要求设计出所需要的theta值？</d><d p="360.84800,1,25,16777215,1583317427,0,5a510386,29452010991910915">就是每层之间有都一个矩阵而已，用来计算下一层参数，感觉他讲的复杂了</d><d p="370.25400,1,25,16777215,1583163732,0,e41bb1e1,29371430614335495">是权重矩阵乘输入矩阵再套g算符</d><d p="282.82500,1,25,16777215,1582967254,0,3a18cac8,29268419138813955">看了两遍手推一遍终于看懂了……</d><d p="192.17900,1,25,16777215,1582871324,0,4291d16a,29218124583141381">theta(1)是一个3*4的矩阵</d><d p="192.91700,1,25,16777215,1582688663,0,cbc1a93b,29122357489565699">theta是矩阵啊兄弟</d><d p="214.24000,1,25,16777215,1582015371,0,7328f538,28769358585004036">z=the transpose theta times x吧</d><d p="197.66900,1,25,16777215,1581928840,0,29dc53d,28723991112843266">不用转置，这个大Theta和小theta代表含义不一样</d><d p="361.42700,1,25,16777215,1581745748,0,5a31a949,28627998230970370">尝试着把式子化成矩阵乘法的形式，然后在把符号对应上去，就可以看懂了</d><d p="628.13400,1,25,16777215,1581491114,0,eea03dc9,28494496991805442">因为包含了所有的可能组合</d><d p="334.73600,1,25,16777215,1581149772,0,41563b7,28315535482552320">矩阵乘以矩阵</d><d p="609.18000,1,25,16777215,1580962139,0,e4693d1b,28217161639526402">最大的问题是为什么这样的神经网络可以解决特征过多难以计算的问题</d><d p="203.52800,1,25,16777215,1580960035,0,7a95c312,28216058298499072">不是一维吗？</d><d p="361.39400,1,25,16777215,1580824072,0,6ccb8d0b,28144774483542016">666</d><d p="367.99700,1,25,16777215,1580643870,0,6d28505f,28050296989024258">只不过加了偏置项</d><d p="586.76000,1,25,16777215,1580639011,0,d2e02652,28047749377163268">似懂非懂</d><d p="296.67700,1,25,16777215,1580468379,0,b33eae4,27958288915103746">要仔细看好a的上标是（1）还是（2）</d><d p="189.83900,1,25,16777215,1580388432,0,b10670e1,27916373737865218">不用，theta的横向量乘以x的列向量</d><d p="193.31900,1,25,16777215,1580374643,0,5b7f29ca,27909144268767232">确实不用</d><d p="190.23300,1,25,16777215,1580295010,0,23aa90ef,27867394022047744">theta现在不是3*4？？？</d><d p="301.47500,1,25,16777215,1580267895,0,90085288,27853177806127106">高代选手表示无压力</d><d p="688.71400,1,25,16777215,1580219281,0,426bbc10,27827690122772480">反向传播拟合权重</d><d p="590.89200,1,25,16777215,1580219215,0,426bbc10,27827655469957120">这已经算深度学习了</d><d p="542.34300,1,25,16777215,1580219162,0,426bbc10,27827627669585920">一个逻辑回归拟合不了复杂的特征，就采用多层感知</d><d p="506.50300,1,25,16777215,1580219080,0,426bbc10,27827584734068736">而神经网络的每一个cell也都是套了类似sigmoid激活函数的</d><d p="186.52700,1,25,16777215,1579789925,0,2dcc762f,27602583750705156">不用个鬼，theta是列向量计算，肯定要转置的</d><d p="585.10300,1,25,16777215,1579673490,0,b83877ee,27541538557919232">现在还是不知道有什么用</d><d p="173.52100,1,25,16777215,1579669325,0,b83877ee,27539354433880068">theta^(1)是3*4的矩阵</d><d p="373.65900,1,25,16777215,1579402535,0,418b9cc3,27399479739023360">看了两遍懂了8成</d><d p="194.79700,1,25,16777215,1579059644,0,5eb6b6e6,27219706404405248">构造过的</d><d p="284.97800,1,25,16777215,1578411845,0,efa679c5,26880072877604864">这段没有问题</d><d p="179.69000,1,25,16777215,1577948140,0,e5ce9ed7,26636958073618436">不用</d><d p="360.43500,1,25,16777215,1577765009,0,13d6dfae,26540944866148356">三脸懵逼</d><d p="177.76900,1,25,16777215,1577764121,0,13d6dfae,26540479017910276">这里是不是要转置？</d><d p="362.97000,1,25,16777215,1577619386,0,554b1ab8,26464596526628864">m*n矩阵脸懵逼</d><d p="319.52400,1,25,16777215,1577468159,0,efa679c5,26385309554966530">因为加了个theta_0</d><d p="284.14900,1,25,16777215,1577468071,0,efa679c5,26385263636250626">还是挺好理解的吧</d><d p="282.59800,1,25,16777215,1576769248,0,e6403e27,26018879228084228">这段要多看几遍，哈哈哈</d><d p="582.29400,1,25,16777215,1576577642,0,e37540a1,25918422411902980">不理解</d><d p="358.93700,1,25,16777215,1576577125,0,e37540a1,25918151146864640">5脸懵逼</d><d p="368.42500,1,25,16777215,1576550893,0,49957cf7,25904398116323396">就是输入矩阵乘权重矩阵然后套了g算符</d><d p="322.65800,1,25,16777215,1576550786,0,49957cf7,25904342355673092">因为有一个bias项</d><d p="530.41900,1,25,16777215,1575710743,0,f822fd07,25463917487587328">无数的逻辑回归组成了神经网络</d><d p="316.83500,1,25,16777215,1575537068,0,ca1ca28a,25372861887152130">为什么是4维？</d><d p="280.18600,1,25,16777215,1575535691,0,ca1ca28a,25372140119261186">感觉好像口误了吧？</d><d p="355.58200,1,25,16777215,1575441889,0,be52a5b4,25322960536993792">二脸懵逼</d><d p="275.94500,1,25,16777215,1573051333,0,f95b5d31,24069620837646340">nmd我裂开了</d><d p="312.63600,1,25,16777215,1572532736,0,97d1d356,23797726577164290">好简单</d><d p="486.14600,1,25,16777215,1571213422,0,4f463abb,23106026161569794">就是说是多重逻辑回归组成了神经网路么</d><d p="701.22000,1,25,16777215,1571208331,0,c3bb8d57,23103357243097088">比心</d><d p="394.48500,1,25,16777215,1569916030,0,a558f6d4,22425819093663744">多元多重复合函数</d><d p="352.61300,1,25,16777215,1568785359,0,bbc1b80d,21833022159454208">一脸蒙逼</d><d p="680.35900,1,25,16777215,1568341593,0,701c284d,21600360683536384">吹爆</d></i>