<?xml version="1.0" encoding="UTF-8"?><i><chatserver>chat.bilibili.com</chatserver><chatid>88849381</chatid><mission>0</mission><maxlimit>1500</maxlimit><state>0</state><real_name>0</real_name><source>k-v</source><d p="291.80100,1,25,16777215,1604223958,0,e6aeba36,40413054259167237">感觉一个不严谨的思路就是把delta看成是求da3=dg/dz * dz, dz=theta.T * dx，外加向量化表示</d><d p="378.83500,5,25,16646914,1604154563,0,3ac20a8b,40376671141363717">没懂的都是还没真正弄懂逻辑回归如何映射成概率问题的</d><d p="378.83500,5,25,16646914,1604154504,0,3ac20a8b,40376640043220999">你们对sigmoid求导试试就知道了 这是sigmoid函数的特性</d><d p="697.08700,1,25,16777215,1604130404,0,1e29d7ba,40364004854464517">反向传播求误差值</d><d p="530.76500,1,25,16777215,1604129193,0,1e29d7ba,40363369849946119">他估计是上辈子没死透</d><d p="468.59200,1,25,16777215,1603770582,0,4a92c268,40175354304790533">+-</d><d p="537.80000,1,25,16777215,1603717705,0,4bb2cd6,40147631562293253">清华的表示看不懂</d><d p="351.84100,1,25,16777215,1603711989,0,605cac09,40144634766163975">普通求导，然后用a表示即可</d><d p="188.42000,1,25,16777215,1603690637,0,3f5e339a,40133440417300485">Concretely</d><d p="94.65500,1,25,16777215,1603690487,0,3f5e339a,40133361779867653">concretely</d><d p="586.07600,1,25,16777215,1603527505,0,6c982231,40047912414085123">需要动手操作</d><d p="320.56000,1,25,16777215,1603526231,0,6c982231,40047243963662341">看不懂呜呜呜</d><d p="430.49900,1,25,16777215,1603457513,0,e94a49e3,40011216084533253">17</d><d p="641.11800,1,25,16777215,1603374598,0,79978d29,39967744942669831">j是什么</d><d p="500.20200,1,25,16777215,1603365035,0,64b36954,39962731171807239">为什么等于零</d><d p="693.51000,1,25,16777215,1603284897,0,6ca71599,39920715907989507">深度学习：从入门到放弃</d><d p="668.78200,1,25,16777215,1603284873,0,6ca71599,39920703016796163">wdtn</d><d p="393.76300,1,25,16777215,1603284560,0,6ca71599,39920539177844739">这就是传说中的BP神经网络吗</d><d p="57.87000,1,25,16777215,1603283932,0,6ca71599,39920209913970693">反向传播算法</d><d p="193.62200,1,25,16777215,1603185201,0,5c3ce452,39868446072111107">..................</d><d p="273.01800,1,25,16777215,1602910304,0,5276cab8,39724320931971075">.*是什么意思</d><d p="17.76200,1,25,16777215,1602909349,0,5276cab8,39723820482297859">这个怎么编程实现呀</d><d p="686.61100,1,25,16777215,1602855955,0,d1b1be60,39695826590629893">j对于l层的第j个权重，i对应于m个样本中的第i个</d><d p="581.57400,1,25,16777215,1602854773,0,d1b1be60,39695206588088327">所以反向传播，是用来减去求偏导的计算量吗?</d><d p="34.37700,1,25,16777215,1602848125,0,8314b447,39691721255157765">这个人戾气怎么这么重</d><d p="671.51300,1,25,16777215,1602835853,0,88c11aac,39685287371603973">这里我已经完全迷失了。。</d><d p="261.27900,1,25,16777215,1602816803,0,3925e593,39675299489120263">祝大家2021年春节快乐</d><d p="191.36200,1,25,16777215,1602764914,0,7d88f0db,39648094621007879">...............................................................................................</d><d p="355.57500,1,25,16777215,1602763881,0,960b8744,39647553108574213">这里并没有反函数啊</d><d p="520.90800,1,25,16777215,1602534209,0,d7b3befd,39527138936750087">先随机一个theta从前往后传，求出最后一层error然后这个error再从后向前传，用来改变这个theta使costfunc变小</d><d p="108.40000,1,25,16777215,1602404728,0,ea8195df,39459253679816707">a(1)也要加偏置吧</d><d p="147.82200,1,25,16777215,1602393749,0,9c5244a4,39453497722142723">输入层是原始数据</d><d p="411.07700,1,25,16777215,1602387414,0,47a0cf7a,39450176302088197">想问下这里的z代表了什么</d><d p="18.45000,1,25,16777215,1602207285,0,b09a52aa,39355736621842437">BP遗传算法？</d><d p="407.91300,1,25,16777215,1602047579,0,81ca0de9,39272004461789191">这里需要推导一下BP过程</d><d p="386.52200,1,25,16777215,1602022020,0,d8bab795,39258604498321413">这个公式怎么来的……</d><d p="716.37800,1,25,16777215,1601869648,0,4c28bb0c,39178717870161923">反向传播用来计算偏导数，可以想到之前的梯度下降法，计算出每个误差项，实现对每一层每个激活单元的参数更新</d><d p="611.51400,1,25,16777215,1601801654,0,b25c44c3,39143069430317059">因为要把m个数据的加在一起</d><d p="18.34600,1,25,16777215,1601371408,0,32ee119d,38917496406278151">另外的17人 你们好呀</d><d p="467.78700,1,25,16777215,1601325210,0,af6c5c2f,38893275139014661">正向逆向这段可以再看看李宏毅的课，俩都听听就会了</d><d p="188.17100,1,25,16777215,1601266276,0,65a7ea4c,38862376830763015">反向传播算法应该是对ML初学者来说最难的部分了</d><d p="687.30300,1,25,16777215,1601200429,0,7c7d6569,38827854002126915">这里的j又是什么</d><d p="185.90500,1,25,16777215,1601133523,0,4cbdb667,38792776321073159">。。。。。</d><d p="525.60200,1,25,16777215,1601126585,0,d297ee41,38789138529910789">你们都是大佬</d><d p="517.65100,1,25,16777215,1601126577,0,d297ee41,38789134369161223">放弃了</d><d p="475.57900,1,25,16777215,1601126476,0,d297ee41,38789081231523847">入门到放弃</d><d p="184.16700,1,25,16777215,1600916393,0,d297ee41,38678937404440581">溜了</d><d p="179.43700,1,25,16777215,1600916387,0,d297ee41,38678934097231877">。。。。。。。</d><d p="584.78800,1,25,16777215,1600781545,0,4769e752,38608238177943559">应该直接是y吧</d><d p="675.34200,1,25,16777215,1600601517,0,9f088233,38513851733377031">你早点说不行吗，这个东西的导数是个人都会算吧，链式法则啊，你花这么久就讲个链式法则？高中都知道的吧</d><d p="598.15400,1,25,16777215,1600601299,0,9f088233,38513737365716995">但是输入层的误差项怎么理解呢，如果这里考虑了delta1，delta1是什么？</d><d p="448.76300,1,25,16777215,1600601195,0,9f088233,38513682890620935">就是牛顿莱布尼兹公式</d><d p="369.16800,1,25,16777215,1600601131,0,9f088233,38513649503436807">就是反函数搞出前面一层的误差</d><d p="268.50800,1,25,16777215,1600601051,0,9f088233,38513607272562693">算出来最后一层的误差然后最后一层调参</d><d p="242.16500,1,25,16777215,1600601030,0,9f088233,38513596222668805">先把最后一层的误差算出来</d><d p="72.30200,1,25,16777215,1600600923,0,9f088233,38513540198825987">暴力调整法</d><d p="28.76500,1,25,16777215,1600600901,0,9f088233,38513528777736197">这只是Cross-entropy cost模型</d><d p="7.33000,1,25,16777215,1600600890,0,9f088233,38513523158417413">Cross-entropy cost</d><d p="157.72000,1,25,52480,1600309346,0,bcc7a718,38360669797482503">欢迎回来</d><d p="355.22800,1,25,16777215,1600255615,0,eb5110c0,38332499261128707">对哪个公式求导呢？对哪个变量求偏导数？</d><d p="665.05200,1,25,16777215,1600108709,0,1a0b5366,38255478489743363">我费了</d><d p="31.53800,1,25,16777215,1600102738,0,489fa0db,38252348162179079">这种问题自己想不明白的话就别学了 就这能力？还是搬砖比较好</d><d p="7.84400,1,25,16777215,1600102672,0,489fa0db,38252313543442439">看不懂的都是不适合学计算机的</d><d p="225.28100,1,25,16777215,1600074887,0,26155808,38237746126913539">y是输入数据，不需要算，保持清醒</d><d p="668.14500,1,25,16777215,1599874525,0,24423b63,38132698662305797">前面应该是没包括偏置项的才对，怎么这里又包括了，矩阵维度根本不对</d><d p="326.36800,1,25,16777215,1599874280,0,24423b63,38132570120519685">微积分链式求导法则</d><d p="304.86600,1,25,16777215,1599874240,0,24423b63,38132548932468739">从连线看，这种方法应该不包括偏置项</d><d p="196.59700,1,25,16777215,1599803994,0,f4d9fc5,38095720196603911">这里翻译有误，是对每一个输出单元</d><d p="468.37700,1,25,16777215,1599735042,0,730bd871,38059569138106371">懵逼中</d><d p="219.17600,1,25,16777215,1599290087,0,9d480dde,37826284815384583">这就是原来的误差函数，只不过换了个名字而已</d><d p="529.60000,1,25,16777215,1599266855,0,6dddbbf0,37814104429690949">你咋不说出生就会</d><d p="266.27000,1,25,16777215,1598679252,0,3df82069,37506031073886211">为什么不平方</d><d p="508.39400,1,25,16777215,1598674815,0,3df82069,37503704826904583">吱</d><d p="353.94900,1,25,16777215,1598672694,0,3df82069,37502592849281093">这里是不是少了一个X?</d><d p="4.05100,1,25,16777215,1598632801,0,3df82069,37481677690241031">激动</d><d p="155.61100,1,25,16777215,1598609951,0,7ff54db1,37469697853095939">再来一遍</d><d p="157.40700,1,25,16777215,1598522400,0,7ff54db1,37423795572572167">噩梦开始的地方</d><d p="406.08400,1,25,16777215,1598338790,0,bc9a421c,37327531306647559">g'（z）就是sigmiod函数在自变量等于z时对应的导数值啊</d><d p="42.14400,1,25,16777215,1598272581,0,205339de,37292818660589571">数学计算还是不难，主要是思想</d><d p="236.57100,1,25,16777215,1598259485,0,65282476,37285952336953351">应该是误差的激活值减去实际值</d><d p="624.97000,1,25,16777215,1598085909,0,3debdd4f,37194948764237829">看了四遍，终于知道我为啥不懂了，千万不要把这个for循环的i当成Delta下标的i</d><d p="697.04300,1,25,16777215,1597467173,0,369edcea,36870552954601479">一脸懵逼</d><d p="226.35300,1,25,16777215,1597286771,0,1fae75d1,36775970257502211">y是数据集给的正确标签</d><d p="154.02800,1,25,16777215,1597242421,0,61cc1d0,36752717894385669">a1时输入层</d><d p="610.44600,1,25,16777215,1596940243,0,5db642a2,36594289710465029">▲下标i 和 for循环的i 是同一个 i 吗</d><d p="604.94300,1,25,16777215,1596847940,0,be5d0a0c,36545896364638213">小写德i到底是啥</d><d p="136.94600,1,25,16777215,1596847679,0,91c38040,36545759394922499">禁止套娃！</d><d p="448.88300,1,25,16777215,1596847560,0,be5d0a0c,36545697025097731">这些下标i是啥意思啊</d><d p="683.58300,1,25,16777215,1596770326,0,bbd6bee5,36505204253786179">nb</d><d p="607.60800,1,25,16777215,1596724433,0,7a857d85,36481142979297285">这个delta为什么能直接加后面的</d><d p="1.57900,1,25,16777215,1596641027,0,f979e7b8,36437414126288899">考数一的都表示没压力</d><d p="609.60100,1,25,16777215,1596639382,0,9dbb66cc,36436551706607621">怎么初始化都好，一般设置为0</d><d p="222.23200,1,25,16777215,1596638765,0,9dbb66cc,36436228331536391">训练集y值是怎么算的</d><d p="408.98200,1,25,16777215,1596611264,0,e75ae703,36421810082807813">将误差变小，梯度下降，确定theta</d><d p="442.43000,1,25,16777215,1596349862,0,ef204474,36284760224432135">我来澄清一下这里大家可能的疑惑：这里g'是对z进行的求导，g是sigmoid函数，z是theta^T*x，a=g(z),求导就行了,只是我觉得好像少了个负号</d><d p="682.13000,1,25,16777215,1596202692,0,879d771b,36207600666148867">哭了</d><d p="344.88300,1,25,16777215,1596156588,0,e4e1b4de,36183428944101383">头晕脑胀，迷迷糊糊</d><d p="344.88300,1,25,16777215,1596156573,0,e4e1b4de,36183421068247045">你们都怎么听懂的。。。。</d><d p="9.43100,5,25,16646914,1595855657,0,973c5451,36025654551511045">51/112</d><d p="257.73600,1,25,16777215,1595836979,0,996c453e,36015861636530179">暑假了喔</d><d p="326.70200,1,25,16777215,1595556023,0,fd4fc5a5,35868559558049797">链式法则 高中内容</d><d p="451.29500,1,25,16777215,1595381147,0,a3f29ff2,35776874400972805">裂开了</d><d p="366.89700,1,25,16777215,1595335005,0,e1f7ee93,35752682812604419">没毛病，求出来一样</d><d p="349.52300,1,25,16777215,1595256595,0,d458d4fe,35711573462876167">我不觉得需要带入sigmoid函数，直接g(z) = a就行吧</d><d p="348.33300,1,25,16777215,1595256532,0,d458d4fe,35711540160102407">确实需要反函数，求出Z关于a的表达式</d><d p="610.12200,1,25,16777215,1595237119,0,42d2c888,35701362288754695">5</d><d p="545.49700,1,25,16777215,1594834115,0,d839b792,35490072055250949">看了好几遍想了好久，我觉得for循环里的i要和大delta下表的i区分开，不是一个东西的</d><d p="606.99900,5,25,16777215,1594731284,0,b4926146,35436159211929603">theta初值怎么确定的啊</d><d p="336.85100,5,25,16777215,1594714035,0,b4926146,35427115638718471">a</d><d p="332.80100,5,25,16777215,1594714025,0,b4926146,35427110283640839">就是末尾会多乘一个sigma（a_i）。由于sigmoid函数的性质，以及我们做分类，各部分概率之和应为1.我猜测sigma(a_i)=1，就和老师这部分蓝色字体一致了</d><d p="332.80100,5,25,16777215,1594714003,0,b4926146,35427098554269703">自己尝试推导了下，注意这里theta是矩阵，而激活函数里的是theta的某一行的行向量。我们没法对向量求导数（如果有求告知，我去学学）。若对向量的分量求导数，可以得到和老师提供的相似的表达式</d><d p="607.97900,1,25,16777215,1594695300,0,a7e976ed,35417293144981507">就是反向链式求偏导</d><d p="11.55700,1,25,16777215,1594533659,0,bcfedc91,35332546423160835">再来一遍！</d><d p="25.67400,1,25,16777215,1594310329,0,70068241,35215457366048775">是的</d><d p="552.87200,5,25,16777215,1594178037,0,38866d0b,35146098076549127">注意这里是对每一个做累加，算的都是单独的数字值，上面的都是向量运算，要注意下标区分</d><d p="552.87200,5,25,16777215,1594177935,0,38866d0b,35146044861317125">大德尔塔是一个用0初始化的空矩阵，下面的累加是针对每一个激活单元做误差值</d><d p="343.12900,1,25,16777215,1594111055,0,5555c01d,35110980318920709">把z(3)代入sigmod函数求导就可以求出来</d><d p="222.52600,1,25,16777215,1593840460,0,5c132009,34969110575054855">应该个锤子哦</d><d p="708.36200,1,25,16646914,1593680395,0,aa0b7852,34885190622380035">错了吧，反向传播是用来为梯度下降服务的。两者不是并列关系</d><d p="533.05300,1,25,16646914,1593679128,0,aa0b7852,34884526268743687">你咋不说娘胎里就学过呢，天才</d><d p="385.23400,1,25,16777215,1593677582,0,aa0b7852,34883715935502341">对这个公式的理解要先拿一个例子出来理解再推及到全部</d><d p="353.08400,1,25,16777215,1593677482,0,aa0b7852,34883663370387461">delta项应该是cost函数对z(L)i的偏导数</d><d p="410.94000,1,25,16777215,1593645156,0,f4d7cfb9,34866715144224775">妙啊</d><d p="305.23900,1,25,16777215,1593589972,0,81194786,34837782953197571">为什么在这一节里计算delta还要点乘偏导数呢，在下一节里说的是delta就是偏导数，只需要计算点乘前面的这一部分就是delta，前面部分是一个向量，点乘另一个向量之后不就变成一个标量了吗</d><d p="658.01700,1,25,16777215,1593515791,0,f6a217b2,34798890632347655">感觉知识的跳跃太大了。。。</d><d p="573.17600,1,25,16777215,1593485143,0,f19f9d89,34782822485983239">越来越看不懂了</d><d p="460.84900,1,25,16777215,1593485027,0,f19f9d89,34782761690071109">懵逼</d><d p="274.07700,1,25,16777215,1593166106,0,2dbf08d8,34615554923823109">51/112</d><d p="448.69100,1,25,16777215,1592974550,0,292031b2,34515124422705157">有什么都没学但一看就懂的么。。怪我想象力太好？</d><d p="597.77600,1,25,16777215,1592919243,0,5ad18398,34486127920414725">这讲算法步骤了，就是刚才的东西啊</d><d p="455.97400,1,25,16777215,1592919078,0,5ad18398,34486041297551367">还好我事先看过BP神经网络的书，不然也是一脸懵逼</d><d p="389.55800,1,25,16777215,1592918835,0,5ad18398,34485913718882311">反向求误差</d><d p="47.87400,1,25,16777215,1592733046,0,6431c3b4,34388506803437571">咋觉得这里的下标很乱呢，一会儿ji一会儿ij</d><d p="345.26400,1,25,16777215,1592665609,0,c5d5a808,34353150306549763">我怎么觉得这里应该使用反函数</d><d p="645.71500,1,25,16777215,1592632886,0,3ba2b0cc,34335993966886917">品，你细品！！</d><d p="430.90600,1,25,16777215,1592632400,0,3ba2b0cc,34335739323875333">可以参考浙江大学胡老师的课程</d><d p="339.93500,1,25,16777215,1592629797,0,3ba2b0cc,34334374631571461">不应该是g(x) * g(1-x) 吗？</d><d p="242.41600,1,25,16777215,1592621057,0,f9975e8d,34329792088637443">弹幕关了，就懂了。</d><d p="133.36300,1,25,16777215,1592620745,0,f9975e8d,34329628789178375">a1没有激活值吗？</d><d p="586.68100,1,25,16777215,1592205588,0,742c255b,34111966745722885">已经跟不上了</d><d p="610.09100,1,25,16777215,1591966901,0,46b8b78c,33986826231873541">大delta上标如果是L的话，那公式中小delta上标就是L+1，但是只有L层啊，L+1层的小delta怎么计算的</d><d p="293.72700,1,25,16777215,1591964761,0,63a0639d,33985704479424515">第一个，这里是不是应该也要乘g'（z（4））</d><d p="218.62400,1,25,16777215,1591964631,0,63a0639d,33985635887874053">这里是不是应该也要乘g'（z（4））</d><d p="697.82900,1,25,16777215,1591944803,0,9e6f61f8,33975240348401667">计算偏导数用的</d><d p="691.07200,1,25,16777215,1591845480,0,ab516041,33923166530699267">有趣</d><d p="396.19200,1,25,16777215,1591845122,0,ab516041,33922979105603591">这个 delta2, delta3 为什么要这么求</d><d p="55.30800,1,25,16777215,1591714804,0,4060e61f,33854654890639363">这个老毕写反了ji</d><d p="500.65000,1,25,16777215,1591466668,0,cc4aae06,33724560210132999">这里的三角符号，我认为相当一个空列表，用于存放损失函数对theta求得的偏导</d><d p="702.35600,1,25,16777215,1591466504,0,cc4aae06,33724474042351621">反向传播可以求得theta值，跟之前的梯度下降类似</d><d p="651.45800,1,25,16777215,1591466226,0,cc4aae06,33724328365785093">楼上正解</d><d p="382.68800,1,25,16777215,1591372292,0,80d3a6f9,33675079642513413">背你大ye，学个基础课都要囫囵吞枣，想必你以后也没啥大成就</d><d p="358.39200,1,25,16777215,1591343355,0,67280ae9,33659908515168263">不懂微积分不请自来</d><d p="155.82800,1,25,16777215,1591283825,0,4539f326,33628697657344007">要来力</d><d p="323.10300,1,25,16777215,1591260796,0,8129f810,33616623692152837">delta 2 3的式子怎么推导来的呀大佬们</d><d p="678.17700,1,25,16777215,1591238613,0,6d0be0fd,33604993630076931">我就说怎么感觉像代价函数。。</d><d p="183.13000,1,25,16777215,1590989830,0,9b55c18f,33474559828557827">可爱的儿童节我为什么要看这个</d><d p="706.10300,1,25,16777215,1590928349,0,27135200,33442326060728327">说白了，就是为了求导</d><d p="689.98500,1,25,16777215,1590925522,0,27135200,33440843535745029">计算量真的好大，计算能力上不去还真搞不出来</d><d p="8.81600,1,25,14811775,1590892630,0,e847cfe0,33423599082668039">很烦这种先入为主的感受灌输，像是一种消极的心理暗示</d><d p="3.02000,1,25,16777215,1590892533,0,e847cfe0,33423547810447367">能不要误导吗 老师的讲法非常完备，新内容总是在铺垫好之后才展开，不懂的地方可能是由于变换有些复杂，自己多花时间理解总会懂的</d><d p="370.48800,1,25,16777215,1590721345,0,4ab052d2,33333795913465863">完蛋，开始听不懂乐</d><d p="665.01700,1,25,16777215,1590655600,0,716d3933,33299326837981191">听不懂怎么试着理解，搞笑了</d><d p="378.37900,1,25,16777215,1590419328,0,26d30b9c,33175452278849541">想那么多干嘛，背下来就好了</d><d p="530.78000,1,25,16777215,1590158797,0,cf081f11,33038859240472583">别阴阳怪气的</d><d p="499.72800,1,25,16777215,1589964178,0,1c315f17,32936822523822087">还真懂了  建议看点课外资料</d><d p="461.82600,1,25,16777215,1589964116,0,1c315f17,32936790282207237">花了两天时间 搞懂了  老师漏了很多东西  不懂正常</d><d p="523.77200,1,25,16777215,1589952038,0,aee0d7d,32930457761349639">这些公式小学二年级就学过</d><d p="505.22900,1,25,16777215,1589793347,0,4f1ed51c,32847257895698439">推导过程一句两句说不清的</d><d p="480.07900,1,25,16777215,1589793277,0,4f1ed51c,32847221350203397">吴老师省略了推导过程，要想搞清楚过程，得自己找资料学习一下</d><d p="306.23900,1,25,16777215,1589761796,0,dca36827,32830716346105859">BP</d><d p="219.29700,1,25,16777215,1589680104,0,4f1ed51c,32787886143176707">aj是算出来的，跟yi肯定有偏差，偏差只能减少，很难完全消除</d><d p="145.42500,1,25,16777215,1589679759,0,4f1ed51c,32787704977031175">输入层为何没有加偏置项？</d><d p="229.44800,1,25,16777215,1589178499,0,c691e681,32524900252516357">目前是训练阶段，又不是测试阶段，我感觉差为零</d><d p="214.50400,1,25,16777215,1589178321,0,c691e681,32524806929776643">既然是训练样本delta不应该为0么</d><d p="225.60300,1,25,16777215,1589091791,0,e3871eb3,32479440678682627">一个训练址。一个真实址</d><d p="332.66600,1,25,16777215,1589082352,0,b2634b65,32474491699331079">这就是求导而已啊....</d><d p="352.59100,1,25,16777215,1589027061,0,6c500a72,32445503475548163">老师讲的是真好，就是我太笨了 。。我再听几遍</d><d p="362.03200,1,25,16777215,1588943943,0,bf593d14,32401925458624519">不考虑吧，bias unit值始终是+1，本身也没有误差</d><d p="165.75000,1,25,16777215,1588943679,0,e940b925,32401787078574083">................</d><d p="654.61300,1,25,16777215,1588676465,0,f7d599e4,32261690281164807">原来的公式不是乘法吗</d><d p="174.67500,1,25,16777215,1588657264,0,b1883c52,32251623284146181">。。。。。</d><d p="174.67500,1,25,16777215,1588657254,0,b1883c52,32251617866153989">。</d><d p="318.87900,1,25,16777215,1588409548,0,c26bef2d,32121748986003463">这里delta 2 3 的公式是咋来的</d><d p="37.94000,1,25,16777215,1588249915,0,34571c59,32038055052836871">第一层没有要估计的参数啊</d><d p="662.53300,1,25,16777215,1588065608,0,2734e1bb,31941425100750853">D又是什么？</d><d p="444.73100,1,25,16777215,1587966818,0,f548e115,31889630688706563">应该是正则化项</d><d p="122.85800,1,25,16777215,1587567792,0,5071223f,31680426155180035">禁止套娃</d><d p="113.73800,1,25,16777215,1587567768,0,5071223f,31680413341057027">禁止套啊！</d><d p="638.06900,5,25,16646914,1587549728,0,ab942539,31670955490672643">循环结束后，大deta是m个训练实例的偏导项的累积值</d><d p="702.26200,1,25,16777215,1587476272,0,fbb83d28,31632443275476997">同样通过梯度下降的方法求出最优解theta</d><d p="228.47000,1,25,16777215,1587461054,0,cb0c3367,31624464656498693">刻舟求剑</d><d p="367.75000,1,25,16777215,1587441983,0,c398a26e,31614465927544839">没考虑叭，考虑了的话维度就不同了，而且bias unit不参与反向传播</d><d p="31.40000,1,25,16777215,1587390258,0,fbb83d28,31587347351470087">因为L层中只有L-1个权重矩阵</d><d p="682.19200,1,25,16777215,1587360367,0,c02c4f59,31571675701051397">lemma下面应该除个m吧</d><d p="661.49500,5,25,16646914,1587212696,0,ab942539,31494253745012743">for循环就是对每一个训练数据i，运用反向传播法算出小deta，然后m个训练数据的小deta可以组成一个大deta</d><d p="506.59700,1,25,16777215,1587211838,0,ab942539,31493803998183431">l表示第几层，i表示输入特征数量，j表示第l层的第j个单元</d><d p="239.65100,1,25,16777215,1587123143,0,e6a29f9e,31447301852495877">没必要杠别人听不懂的吧</d><d p="417.20600,1,25,16777215,1587101325,0,27893883,31435863166025735">请问这样定义delta(2)表达式的原因是什么</d><d p="231.06100,1,25,16777215,1586704144,0,7e32f6c4,31227626062348293">本来就不好理解 多看几遍会好很多</d><d p="659.44700,1,25,16777215,1586694414,0,39c0a9e1,31222524464332803">wysl</d><d p="661.90000,1,25,16777215,1586575784,0,45753278,31160328048345093">听不懂的同学们先试着理解就好</d><d p="227.41800,1,25,16777215,1586574359,0,45753278,31159580943712261">听不懂打出来就懂了???</d><d p="503.46700,1,25,16777215,1586510715,0,8572425a,31126213118918663">吱</d><d p="333.16800,1,25,16777215,1586509948,0,8572425a,31125811349159941">sigmoid函数的导数应该在前面就求过了</d><d p="463.67800,1,25,16777215,1586447960,0,46a46536,31093311556550659">导数脸懵逼</d><d p="299.72600,1,25,16777215,1586412725,0,2e0bdfc2,31074838155624451">这里的theta应该不包含偏置项吧，不然前两项相乘之后跟g'的维度不一致，就无法计算了</d><d p="694.86100,1,25,16777215,1586405334,0,2e0bdfc2,31070963348537349">反向传播到底是干嘛用的？</d><d p="614.33900,1,25,16777215,1586404902,0,2e0bdfc2,31070736773808135">最后一层才是最终输出，y也是最终输出，所以要对应</d><d p="545.04300,1,25,16777215,1586404726,0,2e0bdfc2,31070644810022915">上标i是第i个样本</d><d p="395.38100,1,25,16777215,1586370392,0,2e0bdfc2,31052643613802503">g'到底是对谁求导啊？对z还是对theta？</d><d p="610.62700,1,25,16777215,1586348920,0,4da47994,31041386043146243">为什么只有最后一层可以用a-y呀，前面的层也用a-y不是就不用反向传播了</d><d p="463.53800,1,25,16777215,1586331436,0,f229a066,31032219649179655">一脸懵逼～</d><d p="24.84800,1,25,16777215,1586266709,0,41708cc7,30998284267421703">建议完成编程练习</d><d p="536.06100,1,25,16777215,1586266205,0,befecdb6,30998019562799109">阿伟死了</d><d p="425.90000,1,25,16777215,1586265459,0,aeeee917,30997628485369859">不懂的朋友可以参考一下：深度学习入门，基于python的实现</d><d p="652.62800,1,25,16777215,1586251575,0,3deca7e1,30990349306429447">不会了</d><d p="643.47800,1,25,16777215,1586251565,0,3deca7e1,30990344068792325">wsl</d><d p="328.30700,1,25,16777215,1586230578,0,1a560693,30979340697600003">裂开加一hhh</d><d p="30.10100,1,25,16777215,1586189033,0,59dc2935,30957559271653379">L是指有多少层，但是theta是层与层之间的运算，所以只到L-1</d><d p="496.37100,1,25,16777215,1586142940,0,1a560693,30933393208246279">看懂的吱个声吧</d><d p="672.92200,1,25,16777215,1585986100,0,e80ba47d,30851164119498757">i指的是第几组样本，j指的是这组数据中第l层中第j个值</d><d p="642.35700,1,25,16777215,1585922849,0,e5a94d15,30818002074599427">得到的大他theta矩阵是偏导数矩阵不是误差矩阵</d><d p="375.08400,1,25,16777215,1585752699,0,41708cc7,30728794925957127">因为g(x)是sigmoid函数，它的一个性质是g'(x) = g(x)(1-g(x))</d><d p="652.64000,1,25,16777215,1585720068,0,465e29d3,30711686712786951">这上面的i不是下面的i吧</d><d p="541.81200,1,25,16777215,1585551783,0,c90a2909,30623456674447363">这里下标i和上标i是不是要区分一下</d><d p="380.34200,1,25,16777215,1585530893,0,c90a2909,30612504293933061">看完9.3再看一遍就相对能理解一点了</d><d p="383.66000,1,25,16777215,1585487858,0,f95baa16,30589941762752519">这个时对什么求导</d><d p="315.55400,1,25,16777215,1585390742,0,93c9d79e,30539024955342855">我裂开来</d><d p="392.67300,1,25,16777215,1585379174,0,34671227,30532959723323395">i do not undersatand</d><d p="713.30200,1,25,16777215,1585376541,0,dc83726,30531579658895365">云里雾里</d><d p="470.37700,1,25,16777215,1585216759,0,64bf607a,30447807882592263">这就是b站学习么 爱了爱了</d><d p="445.59900,1,25,16777215,1585216724,0,64bf607a,30447789159219205">从代价函数开始一脸懵逼</d><d p="411.57700,1,25,16777215,1585149846,0,4c1b69ee,30412726289825797">理解不了 死记硬背吧</d><d p="434.78800,1,25,16777215,1584944748,0,7bb0262c,30305195420286979">error是从后往前算的</d><d p="389.59400,1,25,16777215,1584754666,0,b0938e8a,30205537979727875">一事不明，没考虑bias，那怎么求bias的参数</d><d p="281.68000,1,25,16777215,1584674930,0,e979144d,30163733498036227">看这个：机器学习-李宏毅(2019) 的P11有解释这个公式的推导。</d><d p="262.53400,1,25,16777215,1584674781,0,e979144d,30163655046725639">这里吴恩达老师省略了，delta3、delta2怎么推导的证明。</d><d p="578.43800,1,25,16777215,1584586104,0,7a95c312,30117163200675843">这儿i不对啊</d><d p="455.13900,1,25,16777215,1584470176,0,edbf2316,30056383425544195">前面开心的那位，请坐下，陈独秀同学。</d><d p="407.43200,1,25,16777215,1584452874,0,30a5c70c,30047312037806083">说一群憨憨的那个 咖喱人没了？</d><d p="643.15500,1,25,16777215,1584438353,0,dcb8cf42,30039698732744707">或许从维度数入手好一些：m×j = m×j + m×1 * (j + 1)T</d><d p="360.02400,1,25,16777215,1584436683,0,dcb8cf42,30038823002964039">那个g(z3)求的不是a3吗？导数怎么变成这个了？</d><d p="412.87200,1,25,16777215,1584330329,0,82119ce1,29983063197876291">z里面包含了x0theta0 ,咋没关系呢，带进去算g' ，也要用的</d><d p="446.91600,1,25,16777215,1584280742,0,674ea418,29957065443115013">看来不光我自己是个菜鸡</d><d p="645.13800,1,25,16777215,1584277464,0,29f2a1b9,29955346662948935">这一节我看了好久都不明白，动动笔，还是从神经网络那张图开始涂涂画画就明白了</d><d p="645.13800,1,25,16777215,1584277427,0,29f2a1b9,29955327505465349">刚好可以得到整个误差矩阵</d><d p="645.13800,1,25,16777215,1584277406,0,29f2a1b9,29955316154105861">不加ij下标时，通过第l+1层的神经元偏差值乘以l层的输出a的转置</d><d p="645.13800,1,25,16777215,1584277348,0,29f2a1b9,29955286080421891">所以这个误差矩阵的行数是下一层神经元个数，列是当前层输出的个数</d><d p="645.13800,1,25,16777215,1584277287,0,29f2a1b9,29955253771698183">这里i代表下一层的第i个激活神经元，j代表当前层的第j个输出，即下一层第j个输入</d><d p="138.30900,1,25,16777215,1584259362,0,599d7d5f,29945855871025159">在与theta 1 相乘时</d><d p="138.30900,1,25,16777215,1584259354,0,599d7d5f,29945851706605573">这里第一次偏置项好像没有加</d><d p="58.74300,1,25,16777215,1584258787,0,599d7d5f,29945554560614407">下面的求导theta标识是不是错了</d><d p="52.01300,1,25,16777215,1584258743,0,599d7d5f,29945531256537091">theta的排列是不是 j i</d><d p="15.39900,1,25,16777215,1584258558,0,599d7d5f,29945434587791363">那个theta的下标是不是少了东西</d><d p="370.27700,1,25,16777215,1584189560,0,29f2a1b9,29909259770134531">偏导的话不应该是对于输入a^(3)向量里所有的变量都求偏导 得出来的还应该是维度和输入的a^(3)维度一样的向量吧？</d><d p="370.27700,1,25,16777215,1584189477,0,29f2a1b9,29909216022495235">大佬们 我有一事不明，g‘(z^(3))这个地方求偏导为啥会是a^(3).*(1-a^(3))的点乘？这部就会变成一个值了吗</d><d p="53.29000,1,25,16777215,1584076931,0,72bc2358,29850209444954119">i呢</d><d p="676.76000,1,25,16777215,1584068385,0,a00f89ca,29845728893337605">我觉得这个i代表的是l层的权重矩阵对应的i行 j是j列 所以是一个矩阵元素</d><d p="692.80700,1,25,16777215,1583941667,0,82119ce1,29779292429746179">不要问为什么啦，咱又不会证，结论是啥就是啥呗</d><d p="639.65300,1,25,16777215,1583941325,0,82119ce1,29779112888369155">算了。不想了，睡觉，理解这个问题的事情留给明天的我来做</d><d p="451.67800,1,25,16777215,1583939378,0,82119ce1,29778092088098819">就把这当作有上面推导的结果，反正我们再学一年也不一定证的出来...</d><d p="464.02400,1,25,16777215,1583908859,0,1c7851dc,29762091700715527">这应该只是a跟deta的一个函数把</d><d p="458.52500,1,25,16777215,1583737371,0,d4035c59,29672182226354181">一脸懵逼+2</d><d p="664.82000,1,25,16777215,1583723769,0,11a0548c,29665051184988165">这里的i,j指的是什么呀</d><d p="371.82400,1,25,16777215,1583417084,0,1603724a,29504259495034883">没人考虑这个公式是怎么样来的？？</d><d p="637.78700,1,25,16777215,1583384014,0,c1c67cd3,29486921654730755">角标i怎么突然出现了</d><d p="676.68200,1,25,16777215,1583311554,0,ff8d5a87,29448931414376453">惩罚项不是加到J里面吗？为什么加在J的偏导里呢</d><d p="275.98200,1,25,16777215,1583214456,0,70e6c72c,29398024252293123">建议关掉弹幕，书呆子太多</d><d p="273.72100,1,25,16777215,1583117474,0,e0cd6c84,29347177603530757">第四层的误差少写了一个激活函数的求导吧</d><d p="686.63300,1,25,16777215,1583051520,0,4291d16a,29312598869540869">lambda theta 是不是应该乘以1/m ?</d><d p="592.71800,1,25,16777215,1582977179,0,4bc3da91,29273622647930887">2020.2.29</d><d p="417.23000,5,25,15138834,1582942007,0,18f45fe1,29255182493155335">这里应该是省略了链式求导的具体过程，所以看起来比较懵，可参考其他专门介绍神经网络的教程仔细理解</d><d p="276.32400,5,25,16777215,1582855492,0,1cd99f16,29209823782371333">发表一下自己的看法，不对的话请大家指正</d><d p="295.77300,1,25,16777215,1582709932,0,948fb5f9,29133508181491719">theta(3) 是一个4*5的向量 因为现在的步骤是反向传播算法 此时bias项并不算在内所以是4*5</d><d p="366.07400,1,25,16777215,1582355846,0,7d581458,28947865172705280">考虑</d><d p="370.37600,1,25,16777215,1582277532,0,d5472660,28906806330261504">考虑了的 个锤子</d><d p="437.58700,1,25,16777215,1582123926,0,535c6d3,28826272659931138">这块少个符号吧，应该是负梯度</d><d p="659.61900,1,25,16777215,1582092554,0,fab50d15,28809824814759936">红框下面的两个式子相当于之前的theta0，和theta（1-n），通过引入正则式子来惩罚theta（1-n）</d><d p="617.23900,1,25,16777215,1582092393,0,fab50d15,28809739961368580">红框的式子即相当于之前在代价函数中改变每个theta的值，从而求得最优化theta集</d><d p="451.03200,1,25,16777215,1582092023,0,fab50d15,28809546046636032">此处只是给出了一个计算代价函数诸theta偏导数的方法，且此偏导式子没有加正则项</d><d p="4.73500,1,25,16777215,1581946920,0,29dc53d,28733470536630272">这两节看不懂的建议去看李宏毅讲的BP，要更形象</d><d p="480.77400,1,25,16777215,1581927683,0,b281feed,28723384766431236">那个公式推导很麻烦的，工程上直接用</d><d p="404.64200,1,25,16777215,1581566786,0,d2d8d7ca,28534170795900932">蒙了</d><d p="696.87600,4,25,15138834,1581516754,0,a1598f71,28507939451437056">前面的答错了，delta是误差项，上标代表样本编号，i代表层数，j代表第几个</d><d p="391.65000,1,25,16777215,1581339458,0,66ce418b,28414985299820548">导数的链式法则吧</d><d p="367.37400,1,25,16777215,1581052243,0,e1dbed87,28264401805508612">考虑</d><d p="275.11100,1,25,16777215,1580909747,0,551acc3a,28189692914565124">2020/2/5</d><d p="270.00000,1,25,16777215,1580863213,0,6ccb8d0b,28165296077406210">2020/2/5 第一次看</d><d p="668.16800,1,25,16777215,1580568256,0,75222625,28010653615652864">这里把j的那个for loop写出来会好理解一点，主要是最后一个式子</d><d p="413.09600,1,25,16777215,1580560092,0,f6858b7c,28006373223038976">误差传递</d><d p="30.06200,1,25,16777215,1580478114,0,b10670e1,27963392955777026">比如有四层只需要算三次只有三层有参数</d><d p="9.19600,1,25,16777215,1580469426,0,426bbc10,27958837931147264">前面这篇文章对新手真的蛮友好的</d><d p="676.28600,1,25,16777215,1580455572,0,972d52a,27951574592520192">第l层的第i个</d><d p="678.06300,1,25,16777215,1580439052,0,90085288,27942913369440256">我也想问这个问题，下标混乱了有点</d><d p="367.08700,1,25,16777215,1580437367,0,90085288,27942029878099970">考虑了的</d><d p="0.93500,1,25,16777215,1580349740,0,90085288,27896088088805376">要来了要来了</d><d p="634.40500,1,25,16777215,1580291534,0,18fd8d9f,27865571256696832">我一脸懵逼</d><d p="286.80600,1,25,16777215,1580223204,0,f7e9cf14,27829746714804224">新年快乐！</d><d p="252.40600,1,25,16777215,1579852519,0,536a52ce,27635401269706752">祝新年快乐！</d><d p="655.03600,1,25,16777215,1579851682,0,b83877ee,27634962509856768">从这个分类讨论可以看出bias unit应该要考虑</d><d p="396.14900,1,25,16777215,1579778807,0,b83877ee,27596754745032708">?????</d><d p="293.08700,1,25,16777215,1579777672,0,b83877ee,27596159777243136">theta(l)是s_(l+1) * (s_l)+1矩阵吧</d><d p="277.24900,1,25,16777215,1579777117,0,b83877ee,27595868596600836">.*我记得是octave的语法,前面视频提到过,应该是对应元素相乘</d><d p="132.23200,1,25,16777215,1579772981,0,b83877ee,27593700390469632">这里是output of</d><d p="124.63000,1,25,16777215,1579772925,0,b83877ee,27593670871482368">字幕应该是forward propagation</d><d p="60.98200,1,25,16777215,1579772140,0,b83877ee,27593259169087488">theta好像是少了下标i</d><d p="377.82900,1,25,16777215,1579750947,0,f5662250,27582147979640832">g是啥啊</d><d p="30.57800,1,25,16777215,1579435437,0,f5662250,27416729823477764">因为L层中间传递了L-1次啊</d><d p="449.19900,1,25,16777215,1578969769,0,96486873,27172585716318210">z是啥</d><d p="442.74600,1,25,16777215,1578891298,0,bb9ed347,27131444507181058">delta3到delta4跳了步骤</d><d p="236.22400,1,25,16777215,1578468070,0,efa679c5,26909551044329476">这不就是最原始的损失函数吗？</d><d p="693.34200,1,25,16777215,1577657166,0,554b1ab8,26484403895009284">我没懂呀吴老师</d><d p="654.58400,1,25,16777215,1577657101,0,554b1ab8,26484369906991106">这都是啥啊</d><d p="34.09800,1,25,16777215,1576589236,0,5d2019d0,25924500962410500">j→j+1 layer的theta命名为l，所以没有L项</d><d p="274.79200,1,25,16777215,1576559053,0,49957cf7,25908676419649540">这个是对应项相乘吧  要不然结果就不是向量了</d><d p="684.55400,1,25,16777215,1576464792,0,a44beb2f,25859256707710978">lambda应该乘1/m</d><d p="233.47300,1,25,16777215,1576245646,0,1aeaa59a,25744360911405056">听不懂的：误差就是假设的输出减去真是的输出</d><d p="692.29800,1,25,16777215,1576230504,0,ec072dfd,25736422115770372">第i个样本的第j个个特征</d><d p="383.79600,1,25,16777215,1575861951,0,fa697031,25543194036404226">没考虑bias</d><d p="34.64900,1,25,16777215,1575861195,0,fa697031,25542797642170368">因为K指的是隐藏层（我们把输入层和输出层也当错隐藏层）的层数，那么参数的层数就是K-1，比隐藏层少一层</d><d p="47.31700,1,25,16777215,1575462775,0,be52a5b4,25333910761635842">好像是</d><d p="20.34300,1,25,16777215,1575462101,0,be52a5b4,25333557541470208">再看一遍就知道了</d><d p="476.84100,1,25,16777215,1575442904,0,ba7bbbff,25323492869144576">看了弹幕也并不觉得看明白了啥ojz</d><d p="683.48100,1,25,16777215,1575033776,0,cb10c3f2,25108992141819904">i 应该对应的是某一层的第几个样本</d><d p="683.48100,1,25,16777215,1575033758,0,cb10c3f2,25108982630711300">I</d><d p="475.67800,1,25,16777215,1575033200,0,cb10c3f2,25108689846272002">最后一个应该都推不出来 应该简化了</d><d p="25.46600,1,25,16777215,1575031057,0,cb10c3f2,25107566473248770">谁知道为啥L到l-1而不是L</d><d p="211.96700,1,25,16777215,1575015728,0,7ea22138,25099529366798338">听不懂</d><d p="292.89100,1,25,16777215,1574760417,0,43dc3485,24965672901017604">之后不是点乘吗</d><d p="445.21800,1,25,16777215,1574671475,0,1ee2370,24919041918369794">看到弹幕开心多了，之前没白学，一看就明白，很简单</d><d p="380.03100,1,25,16777215,1573564711,0,b6f0bbd2,24338778866843648">为什么要乘以导数项</d><d p="685.10400,1,25,16777215,1573314256,0,dd032886,24207468051562496">不用和理解太细、这里只是初步的介绍原理、交给pc解决吧</d><d p="467.70600,1,25,16777215,1572579823,0,97d1d356,23822413847330818">就是数学过程有点不明白</d><d p="4.88700,1,25,16777215,1572311076,0,4deb2266,23681513105129472">网友小耿在哪？</d><d p="364.80300,1,25,16777215,1572186315,0,5b2c9905,23616102429884420">考虑了bias unit</d><d p="295.24400,1,25,16777215,1572186040,0,5b2c9905,23615958405873668">是4*5，+1已经算进去了</d><d p="6.75800,5,25,15138834,1572012216,0,2ff39599,23524824159092736">希望能帮到大家</d><d p="3.49800,5,25,15138834,1572012177,0,2ff39599,23524804184768512">里面有网友小耿的分析，很到位，只需5-10分钟即可看完</d><d p="0.37800,5,25,15138834,1572012097,0,2ff39599,23524762144210946">9.2和9.3看不明白的同学，很正常，因为吴老师省略了一些推导过程</d><d p="5.98000,1,25,16777215,1571367173,0,c3bb8d57,23186635932303360">第一遍没懂，来第二遍</d><d p="441.53500,1,25,16777215,1571366610,0,c3bb8d57,23186340725653506">看到 弹幕我踏实多了，我本来以为就我自己整不明白 。。。</d><d p="294.61300,1,25,16777215,1571318027,0,15412736,23160869331402752">theta(3)是4*6矩阵，转置之后是6*4，德尔塔(4)是4*1的列向量，所以可以乘</d><d p="290.19600,1,25,16777215,1571317930,0,15412736,23160818411503616">theta(3)是4*6矩阵</d><d p="446.11800,1,25,16777215,1571224621,0,41403e04,23111897696960512">一脸懵逼+1</d><d p="474.36200,1,25,16777215,1570812491,0,5bcf0370,22895822860451840">公式劝退</d><d p="59.51000,1,25,16777215,1570672820,0,f287d22d,22822595000270852">是啊</d><d p="673.74500,1,25,16777215,1570626066,0,7c24ef0a,22798082614755330">这个delta的下标i对应的是第几个样本？还是网络里的某层的某个神经元</d><d p="392.25400,1,25,16777215,1570368608,0,946da2e8,22663100245213188">Delta就是J(theta)对Z的导数</d><d p="38.96200,1,25,16777215,1570285921,0,946da2e8,22619748608507906">中括号括在y前面更好吧</d><d p="361.22500,1,25,16777215,1569988561,0,a558f6d4,22463846401703936">不考虑</d><d p="287.80700,1,25,16777215,1569988171,0,a558f6d4,22463641662521344">theta是4x5的矩阵吧</d><d p="439.06800,1,25,16777215,1569986518,0,a558f6d4,22462775413964800">我还以为就我一个菜鸡，大佬都不发弹幕，我也不敢说</d><d p="2.15800,1,25,16777215,1569984402,0,a558f6d4,22461665677672448">一大坨公式</d><d p="0.00000,1,25,16777215,1569765339,0,26b0ea2f,22346813714464768">哈哈</d><d p="283.49100,1,25,16707842,1569638999,0,c1f0f089,22280575077842944">前两项一乘不成了实数了吗</d><d p="477.56700,1,25,16777215,1566371268,0,1032b8c5,20567342788378624">关于推导西瓜书上更详细一些</d><d p="57.69700,5,25,16765698,1566291152,0,a3fb9bfc,20525339158511616">下标少了个i吧</d><d p="359.43300,1,25,16777215,1565358758,0,c598a0ec,20036496036724736">这里要考虑bias units吗？</d><d p="434.97200,1,25,16777215,1565159416,0,83a39619,19931983752200192">一脸懵逼</d></i>