<?xml version="1.0" encoding="UTF-8"?><i><chatserver>chat.bilibili.com</chatserver><chatid>88849782</chatid><mission>0</mission><maxlimit>1500</maxlimit><state>0</state><real_name>0</real_name><source>k-v</source><d p="60.63000,1,25,16777215,1604408525,0,1e29d7ba,40509820401352709">这几句说的可真够绕的哈哈</d><d p="511.87700,1,25,16777215,1603666347,0,c19b976d,40120705596522503">难道在一起看么，同学哈哈哈哈</d><d p="480.27400,1,25,16777215,1603666289,0,c19b976d,40120674888450053">前面走神那个！！我来回看好几遍这个切换了</d><d p="509.78500,1,25,16777215,1603363735,0,1787402c,39962049785626627">是单纯的大量数据没有用。</d><d p="496.79800,1,25,16777215,1603276784,0,c4ff29fa,39916462344241157">所以可以总结为，训练数据不是越多越好，也和你训练模型的复杂度有关</d><d p="496.79800,1,25,16777215,1603276749,0,c4ff29fa,39916443973713923">因为你的特征太少，即使你给了这个经纪人很多训练数据，他还是没办法准确预测，因为特征太少</d><d p="496.79800,1,25,16777215,1603276700,0,c4ff29fa,39916417941241863">这节讲的重点是数据和特征的关系，例如，你就算找一个房地产经纪人，只给他房子有多大，他也无法准确给出价格</d><d p="407.47000,1,25,16777215,1603185357,0,5276cab8,39868528175611911">各位人类学家们好</d><d p="219.72200,1,25,16777215,1603185000,0,5276cab8,39868341000601607">样本怎么收集那么多呀</d><d p="154.27900,1,25,16777215,1603184893,0,5276cab8,39868284649603079">纳音贝斯</d><d p="501.54300,1,25,16777215,1603014444,0,f1b08379,39778920330952711">我也是</d><d p="492.45800,1,25,16777215,1603014438,0,f1b08379,39778917206196227">哈哈哈哈哈</d><d p="23.57400,1,25,16777215,1602899646,0,548a05e0,39718733393952775">hello</d><d p="576.45900,1,25,16777215,1602589413,0,b2d1662d,39556081852088327">J（train）~J（cv）</d><d p="499.19500,1,25,16777215,1602426925,0,b09a52aa,39470891348787203">我觉得老师在向无监督学习慢慢过渡</d><d p="9.08800,5,25,15138834,1602414151,0,fb2bdd2b,39464193915617285">69/112</d><d p="608.38300,1,25,16777215,1602384345,0,f0d25ef1,39448566887874567">怎么就困了呢</d><d p="581.04900,1,25,16777215,1602052753,0,81c48ed1,39274717636984837">光天化日朗朗乾坤，一起睡觉带我一个</d><d p="501.84100,1,25,16777215,1602033670,0,476ce6e9,39264712376975363">这节在告诉你大量数据有没有用</d><d p="111.38200,1,25,16777215,1601900566,0,d297ee41,39194927649259525">应试教育就这样吧</d><d p="88.09400,1,25,16777215,1601900543,0,d297ee41,39194915451699207">就算是之前学过都不会用到里面俩</d><d p="69.55100,1,25,16777215,1601900524,0,d297ee41,39194905724583939">需要补的东西太多</d><d p="632.54300,1,25,16777215,1600934928,0,81d678b,38688655286468611">然后绝望的发现计算力不够23333</d><d p="624.55400,1,25,16777215,1598434541,0,4c910636,37377732438917125">醒醒，点你名了</d><d p="416.89900,1,25,16777215,1598434337,0,4c910636,37377625215729671">翻译挨打</d><d p="252.76700,1,25,16777215,1598434205,0,4c910636,37377555948896261">刷到带错误答案的题算啥</d><d p="606.47900,1,25,16777215,1597831115,0,4327b29e,37061363453394949">刚睡醒</d><d p="599.17600,1,25,16777215,1597752859,0,1b6e9f2e,37020334544650245">我睡着了</d><d p="167.13700,1,25,16777215,1597214396,0,a3edf14,36738024747302915">可爱贝叶斯</d><d p="664.97800,1,25,16777215,1596792134,0,91493fff,36516637966860293">最后一句翻译有问题，是if you can 不是if you cant 吧</d><d p="14.37000,5,25,16646914,1596071035,0,973c5451,36138574460485635">69/112</d><d p="530.74600,1,25,16777215,1595944312,0,49b7304b,36072134843826183">21点51分</d><d p="228.63600,1,25,16777215,1595821576,0,b4fdba14,36007786114973703">横坐标对应训练集大小，纵坐标表示在交叉验证集上的准确率吧</d><d p="572.57200,1,25,16777215,1595615129,0,6ccb74c6,35899548140306439">这里在说啥。。</d><d p="255.55800,1,25,16777215,1595322599,0,4342fa90,35746178221998083">不只是刷题，还要看你能从题目中得到的特征够不够多，不然模型的偏差大你刷再多题都没用</d><d p="73.20400,1,25,16777215,1594802365,0,14fd5a04,35473425847287815">那咋办嘛</d><d p="106.10600,1,25,16777215,1594358191,0,23501a57,35240550865567747">CBOW登场，BERT登场</d><d p="155.99000,1,25,16777215,1593399968,0,9e6f61f8,34738165897494535">天真贝叶斯</d><d p="494.11700,1,25,16777215,1593233593,0,8076a951,34650937803931651">这节到底再讲啥</d><d p="477.49100,1,25,16777215,1593225329,0,ab516041,34646605123551237">反复走神</d><d p="457.08200,1,25,16777215,1592701081,0,bcf76cf7,34371748106338307">假如你是那个专家，你觉得贵根据已有数据是否足以让你得出正确的预测。</d><d p="379.59800,1,25,16777215,1592700846,0,bcf76cf7,34371624835219461">数据决定的是下线，算法是充分榨干数据的价值，决定模型上限。</d><d p="255.72800,1,25,16777215,1592700218,0,bcf76cf7,34371295667290119">数据决定下限，算法决定上限。</d><d p="650.08300,1,25,16777215,1591596104,0,a1dfe232,33792421985779715">下课吃饭了</d><d p="252.62100,1,25,16777215,1591441010,0,aa1f1fe3,33711108171235399">老师之前强调过不是样本越多越好啊</d><d p="228.85800,1,25,16777215,1591002889,0,1521ab94,33481406298980357">过拟合两个原因，模型太复杂，样本太少</d><d p="155.14900,1,25,16777215,1591002800,0,1521ab94,33481359725953031">天真贝叶斯</d><d p="14.88800,1,25,16777215,1590977345,0,6bac3325,33468013939785731">hello</d><d p="56.69100,1,25,16777215,1590578648,0,b892c94a,33258981997150213">我感觉机器学习的知识点太琐碎了</d><d p="632.50300,1,25,16777215,1590485605,0,b9561daa,33210200713854981">想到的人类的学习，好的环境+努力，完美</d><d p="208.59100,1,25,16777215,1590313136,0,94bba085,33119777254801415">features增多同时data set少，才会过拟合</d><d p="13.11800,1,25,16777215,1590063715,0,378ad80,32989008633004039">hello</d><d p="582.97900,1,25,16777215,1589979877,0,739f5ffc,32945053312745479">我也要睡了</d><d p="374.04300,1,25,16777215,1589864838,0,fa6a41c,32884739935830021">除非 我预测之后，就买了它</d><d p="379.87300,1,25,16777215,1589447031,0,6bf5f5f4,32665688844795907">学区房</d><d p="475.59700,1,25,16777215,1589265815,0,3db4b06b,32570679065313287">但是这仅限于简单的case吧，如果是feature多或者复杂的 就不太好让人解</d><d p="116.19100,1,25,16777215,1589015782,0,70882979,32439589943115779">自然语言理解</d><d p="254.43900,1,25,16777215,1588849590,0,56945880,32352457646407685">很简单，训练数据足够大，考试全部是做过的题</d><d p="574.22300,1,25,16777215,1588842310,0,217da796,32348640414531591">证明</d><d p="151.12400,1,25,16777215,1588790808,0,37070b90,32321638576422915">现在查重。。就是这个方差原理</d><d p="219.75400,1,25,16777215,1588735244,0,8c828548,32292507207860229">这里的准确度是针对训练集还是交叉验证集啊</d><d p="108.01700,1,25,16777215,1588696091,0,3ab4b8c3,32271979789156359">这里需要一个中学生就行</d><d p="634.48000,1,25,16777215,1588582618,0,78a4faff,32212487358644227">每次听见老师说的“so”就感觉要下课了</d><d p="632.20700,1,25,16777215,1588582576,0,78a4faff,32212465321771011">每次听见老师说的so</d><d p="250.84400,1,25,16777215,1588582258,0,78a4faff,32212298398433285">弹幕学以致用</d><d p="581.49100,1,25,16777215,1588579902,0,bf86d4b7,32211063222042627">有没有喜欢帅哥的帅哥</d><d p="115.89600,1,25,16777215,1588164476,0,e67b7c49,31993260270419973">完形填空人工智能？</d><d p="589.31100,1,25,16777215,1588148235,0,ebce8a9f,31984745682829315">你们先睡，我再偷学会</d><d p="231.04400,1,25,16777215,1587806034,0,fe8a66f6,31805333425356805">这是看精确度的，拟合没关系吧</d><d p="216.33700,1,25,16777215,1587459926,0,8572425a,31623873459912709">样本量大不容易过拟合</d><d p="376.45100,1,25,16777215,1587032965,0,d9092dbc,31400022925377541">数据决定了机器学习的上限</d><d p="247.13000,1,25,16777215,1586942399,0,7f77cb0a,31352540237398021">刷过复杂题过拟合吧</d><d p="204.39100,1,25,16777215,1586799827,0,7e32f6c4,31277791409864711">横坐标是训练的数据集 不是特征量</d><d p="630.70400,1,25,16777215,1586748547,0,67b76002,31250905900253191">low</d><d p="101.31700,1,25,16777215,1586666925,0,bb093f70,31208112594616323">完形填空</d><d p="205.04600,1,25,16777215,1586542816,0,2e0bdfc2,31143043317366787">数据量小才会过拟合吧？</d><d p="643.65400,1,25,16777215,1586448948,0,95820e35,31093829505384455">这节把握以下两点：.   .</d><d p="146.02100,1,25,16777215,1586448287,0,95820e35,31093483074224131">朴素贝叶斯</d><d p="220.84700,1,25,16777215,1586255682,0,de35c427,30992502437707783">过拟合是因为选择的模型太复杂吧</d><d p="574.68400,1,25,16777215,1586224268,0,6bb3910c,30976032604422149">有空一起睡觉呀</d><d p="417.33800,5,25,16646914,1585815188,0,977afb10,30761556910276615">专家（人）</d><d p="211.31400,1,25,16777215,1585399863,0,4033db9,30543806862458951">数据越多也就越不会过拟合</d><d p="569.06400,1,25,16777215,1585389274,0,958da359,30538255171059779">前面的别睡</d><d p="240.92800,1,25,16777215,1585297804,0,b851a711,30490298509426691">刷题就是验证集嘛，刷错题就容易导致过拟合了</d><d p="242.73400,1,25,16777215,1585059964,0,7bb0262c,30365602150875139">感觉就是如果你考虑了所有可能取值和结果你的正确率肯定上升因为都见过</d><d p="624.94500,1,25,16777215,1584887632,0,51f68c7a,30275250309562371">这里是low variance吧？</d><d p="198.38000,1,25,16777215,1584701684,0,3a4add14,30177760270352389">这不会过拟合吗</d><d p="442.09000,1,25,16777215,1584415655,0,ff8d5a87,30027798589997059">human prices??</d><d p="668.43800,1,25,16777215,1584260241,0,72bc2358,29946317333069829">这思路太好了</d><d p="575.56100,1,25,16777215,1584169446,0,aeb9b4e7,29898713944555527">有人没有</d><d p="555.00400,1,25,16777215,1584169425,0,aeb9b4e7,29898703173582853">我要睡着了</d><d p="244.51400,1,25,16777215,1584000899,0,93288dea,29810347124195335">电脑能记住每组数据，你能记住刷过的每一道题吗</d><d p="401.07100,1,25,16777215,1583240756,0,87351dff,29411813160910853">人类学家哈哈哈哈哈哈</d><d p="337.85600,1,25,16777215,1583216487,0,a722038e,29399088945430533">条件概率</d><d p="664.40000,1,25,16777215,1581257909,0,b83877ee,28372230441271296">can do both</d><d p="175.21700,1,25,16777215,1581238616,0,b83877ee,28362114956001284">outer rooms-&gt;algorithms</d><d p="448.94400,1,25,16777215,1581219738,0,27deb06d,28352217688309764">这种思路好棒啊！</d><d p="630.60700,1,25,16777215,1580959634,0,b10670e1,28215848029126658">更多的方差值不等于方差大</d><d p="406.98700,1,25,16777215,1580782941,0,90085288,28123210138517504">神tm人类学家，明明是人类学家（狗头）</d><d p="657.48900,5,25,16765698,1580644726,0,426bbc10,28050745898565634">那么收集大量有效的数据往往是有帮助的</d><d p="657.48900,5,25,16765698,1580644709,0,426bbc10,28050736687874052">并且你的算法本身就是低偏差、高方差的模型（如神经网络）</d><d p="431.95500,1,25,16777215,1580643181,0,426bbc10,28049935928131588">高考英语选词填空</d><d p="421.40200,1,25,16777215,1580643154,0,426bbc10,28049921684275202">我可能会选too</d><d p="325.69300,1,25,16777215,1580643028,0,426bbc10,28049855482953728">上下文</d><d p="242.26800,1,25,16777215,1578996276,0,bb9ed347,27186483139444736">刷题就是梯度下降</d><d p="625.63800,1,25,16777215,1578657361,0,554b1ab8,27008793881083904">难道不是"little variance"吗？怎么会是'more variance''?</d><d p="420.06200,1,25,16777215,1578656597,0,554b1ab8,27008393843572736">不包括我这个英语渣了哈哈</d><d p="238.65800,1,25,16777215,1578656387,0,554b1ab8,27008283595243522">引申到学习上就是，大量刷题还是最有效的学习方法</d><d p="629.24500,5,25,16777215,1575948020,0,86f394b,25588319344656388">多参数保证偏差足够小，大量数据保证方差小，合二为一完美</d><d p="390.12400,1,25,16777215,1575204047,0,a2d087af,25198262835740672">hello world</d><d p="422.53200,1,25,16777215,1570951111,0,8bb0d3ec,22968499895271426">这个教程的英语字幕证明了人工智能在这方面不行</d><d p="406.37100,1,25,16777215,1570950969,0,8bb0d3ec,22968425144385538">人类学家 anthropologist</d><d p="395.11500,1,25,16777215,1570089812,0,c1f0f089,22516931020455940">神tm人类学家</d><d p="140.74400,1,25,16777215,1567349139,0,2dd91ab5,21080029001678848">naive</d><d p="261.42900,1,25,16777215,1563027419,0,3bdd6805,18814203056881668">these items-&gt;these algorithms</d></i>